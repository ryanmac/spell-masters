{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the word lists JSON file\n",
    "with open('src/data/word_lists.json', 'r') as file:\n",
    "    word_lists = json.load(file)\n",
    "\n",
    "# Extract levels and metadata\n",
    "levels = word_lists.get(\"levels\", {})\n",
    "metadata = word_lists.get(\"metadata\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Define Ollama API parameters\n",
    "url = \"http://localhost:11434/api/generate\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "def generate_sentences(model, word, max_tokens=250):\n",
    "    # Few-shot prompt\n",
    "    prompts = [\n",
    "        f\"Role: You are an expert educational sentence creator. Objective: Generate 6 concise example sentences, each on a new line, using the word '{word}' exactly as given, without changing its form. Ensure each sentence is educational and student-friendly, subtly hinting at the word's meaning:\\n\\nWord: {word}\\n1. \",\n",
    "        f\"Write 6 concise example sentences, each on a new line, using the word '{word}' exactly as provided, without altering its form. Make sure each sentence is educational and student-friendly, with hints about the word's meaning:\\n\\nWord: {word}\\n1. \",\n",
    "        f\"You are a teacher. Write 6 concise example sentences, each on a new line, that use the word '{word}' exactly as it is written, without any changes in form. The sentences should be educational and student-friendly, subtly revealing the word's meaning:\\n\\nWord: {word}\\n1. \",\n",
    "        f\"Generate 6 example sentences that each use the word '{word}' in its exact form. The sentences should be concise, educational, and student-friendly, and should hint at the word's meaning without changing its form:\\n\\nWord: {word}\\n1. \",\n",
    "        f\"As a language expert, create 6 concise example sentences that use the word '{word}' verbatim, keeping the word in its exact form. Each sentence should be educational and accessible to students, giving clues to the word's meaning:\\n\\nWord: {word}\\n1. \",\n",
    "        f\"Create 6 concise example sentences using the word '{word}' exactly as provided, without any variations like plurals or different tenses (e.g., '{word}s', '{word}ly'). Each sentence should be educational, student-friendly, and hint at the word's meaning:\\n\\nWord: {word}\\n1. \",\n",
    "        f\"Generate 6 concise sentences where the word '{word}' is used exactly as given, with no changes in spelling, tense, or form. Ensure each sentence is educational and appropriate for students, providing hints to the word's meaning:\\n\\nWord: {word}\\n1. \",\n",
    "        f\"Write 6 concise sentences using the word '{word}' exactly as provided, ensuring the word appears only once in each sentence, without any variations in form. Each sentence should be educational and suitable for students, subtly indicating the word's meaning:\\n\\nWord: {word}\\n1. \",\n",
    "        f\"As a sentence creator, generate 6 example sentences where the word '{word}' is used exactly as given, with no alterations (e.g., no plurals, no derivations). Each sentence should be clear, educational, and student-friendly, with a hint towards the word's meaning:\\n\\nWord: {word}\\n1. \",\n",
    "        f\"Create 6 sentences where the word '{word}' is used exactly as provided, without any changes. Do not use variations like '{word}s' or '{word}ly'. Ensure the sentences are educational, student-friendly, and subtly reveal the meaning of the word:\\n\\nWord: {word}\\n1. \"\n",
    "    ]\n",
    "    prompt = random.choice(prompts)\n",
    "    \n",
    "    # API request\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0.4\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "        return []\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(e)\n",
    "        return []\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "    response_text = response.json().get(\"response\", \"\")\n",
    "    \n",
    "    # Split sentences\n",
    "    sentences = response_text.split('\\n')\n",
    "    # Throw out the first sentence\n",
    "    sentences = sentences[1:]\n",
    "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "    # Replace any leading numbers (ex. \"1. \" or \"10. \") with an empty string    \n",
    "    sentences = [re.sub(r\"^\\d+\\.\\s*\", \"\", sentence) for sentence in sentences]\n",
    "\n",
    "    # Replace any leading - with an empty string\n",
    "    sentences = [re.sub(r\"^-\", \"\", sentence) for sentence in sentences]\n",
    "\n",
    "    # If a sentence is in this format: `sentence (definition)`, remove the definition\n",
    "    sentences = [re.sub(r\"^(.*)\\s+\\(.*\\)$\", r\"\\1\", sentence) for sentence in sentences]\n",
    "\n",
    "    # If a sentence starts and ends with double quotes, remove them\n",
    "    sentences = [re.sub(r\"^\\\"(.*)\\\"$\", r\"\\1\", sentence) for sentence in sentences]\n",
    "\n",
    "    # Trim all of the sentences\n",
    "    sentences = [sentence.strip() for sentence in sentences]\n",
    "\n",
    "    # Filter out any sentences that are too short\n",
    "    sentences = [sentence for sentence in sentences if len(sentence) >= 10]\n",
    "\n",
    "    # Case-insensitive filtering sentences to keep only those sentences that contain the word\n",
    "    valid_sentences = [sentence for sentence in sentences if re.search(r\"\\b\" + word + r\"\\b\", sentence, re.IGNORECASE)]\n",
    "\n",
    "    return valid_sentences[:5]  # Return the first 3 valid sentences\n",
    "\n",
    "def generate_sentences_recursive(model, word, n=5):\n",
    "    sentences = generate_sentences(model, word)\n",
    "    if len(sentences) >= n:\n",
    "        return sentences[:n]\n",
    "    else:\n",
    "        return sentences + generate_sentences_recursive(model, word, n - len(sentences))\n",
    "\n",
    "def generate_sentences_recursive_with_max_loop_count(model, word, n=5, loop=10):\n",
    "    sentences = generate_sentences(model, word)\n",
    "    loop_count = 1\n",
    "    while len(sentences) < n and loop_count < loop:\n",
    "        sentences += generate_sentences(model, word)\n",
    "        loop_count += 1\n",
    "    return sentences[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the generated sentences\n",
    "output_data = {}\n",
    "\n",
    "# Iterate through each level\n",
    "for level, data in levels.items():\n",
    "    words = data.get(\"words\", [])\n",
    "    bonus_words = data.get(\"bonus\", [])\n",
    "    \n",
    "    # Process each word\n",
    "    for word in words + bonus_words:\n",
    "        sentences = generate_sentences_recursive(model=\"openhermes\", word=word, n=5)\n",
    "        if len(sentences) >= 5:\n",
    "            output_data[word] = sentences\n",
    "            print(f\"{word}:\")\n",
    "            for sentence in sentences:\n",
    "                print(f\"\\t{sentence}\")\n",
    "        else:\n",
    "            print(f\"Warning: Less than 3 valid sentences generated for word '{word}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences generated and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the output data to a new JSON file\n",
    "# with open('src/data/word_sentences.json', 'w') as outfile:\n",
    "#     json.dump(output_data, outfile, indent=2)\n",
    "\n",
    "# print(\"Sentences generated and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3993 existing entries loaded.\n",
      "Existing data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# File path where the output will be saved\n",
    "file_path = 'src/data/word_sentences.json'\n",
    "\n",
    "# Load existing data if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, 'r') as infile:\n",
    "        existing_data = json.load(infile)\n",
    "        print(f\"{len(existing_data)} existing entries loaded.\")\n",
    "else:\n",
    "    existing_data = {}\n",
    "\n",
    "print(\"Existing data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the word list data\n",
    "\n",
    "import json\n",
    "\n",
    "# Load the word lists JSON file\n",
    "with open('src/data/word_lists.json', 'r') as file:\n",
    "    word_lists = json.load(file)\n",
    "\n",
    "# Extract levels and metadata\n",
    "levels = word_lists.get(\"levels\", {})\n",
    "metadata = word_lists.get(\"metadata\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Processing level 1...\n",
      "\n",
      "\n",
      "Level 1 processed 0 in 0.00 seconds.\n",
      "Average time per word: 0.00 seconds.\n",
      "Total time elapsed: 0.00 seconds.\n",
      "Average time per 200 words: 0.00 minutes.\n",
      "\n",
      "\n",
      "\n",
      "Processing level 2...\n",
      "\n",
      "\n",
      "Level 2 processed 0 in 0.00 seconds.\n",
      "Average time per word: 0.00 seconds.\n",
      "Total time elapsed: 0.00 seconds.\n",
      "Average time per 200 words: 0.00 minutes.\n",
      "\n",
      "\n",
      "\n",
      "Processing level 3...\n",
      "\n",
      "\n",
      "Level 3 processed 0 in 0.00 seconds.\n",
      "Average time per word: 0.00 seconds.\n",
      "Total time elapsed: 0.00 seconds.\n",
      "Average time per 200 words: 0.00 minutes.\n",
      "\n",
      "\n",
      "\n",
      "Processing level 4...\n",
      "\n",
      "\n",
      "Level 4 processed 0 in 0.00 seconds.\n",
      "Average time per word: 0.00 seconds.\n",
      "Total time elapsed: 0.00 seconds.\n",
      "Average time per 200 words: 0.00 minutes.\n",
      "\n",
      "\n",
      "\n",
      "Processing level 5...\n",
      "\n",
      "\n",
      "Level 5 processed 0 in 0.00 seconds.\n",
      "Average time per word: 0.00 seconds.\n",
      "Total time elapsed: 0.00 seconds.\n",
      "Average time per 200 words: 0.00 minutes.\n",
      "\n",
      "\n",
      "\n",
      "Processing level 6...\n",
      "\n",
      "\n",
      "Level 6 processed 0 in 0.00 seconds.\n",
      "Average time per word: 0.00 seconds.\n",
      "Total time elapsed: 0.00 seconds.\n",
      "Average time per 200 words: 0.00 minutes.\n",
      "\n",
      "\n",
      "\n",
      "Processing level 7...\n",
      "\n",
      "\n",
      "Processing benefiting 169/600...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Iterate through each level\n",
    "for level, data in levels.items():\n",
    "    level_start_time = time.time()\n",
    "    words = data.get(\"words\", [])\n",
    "    bonus_words = data.get(\"bonus\", [])\n",
    "\n",
    "    # For new levels, print the level name\n",
    "    print(f\"\\n\\n\\nProcessing level {level}...\\n\\n\")\n",
    "    \n",
    "    # Process each word\n",
    "    words_processed = []\n",
    "    for i, word in enumerate(words + bonus_words):\n",
    "\n",
    "        if word in existing_data:\n",
    "            # check to see if there are 5 sentences\n",
    "            if len(existing_data[word]) >= 5:\n",
    "                # print(f\"Skipping '{word}': already processed.\")\n",
    "                continue\n",
    "\n",
    "        if (i+1) % 1 == 0:\n",
    "            print(f\"Processing {word} {i+1}/{len(words + bonus_words)}...\")\n",
    "\n",
    "        word_start_time = time.time()\n",
    "\n",
    "        sentences = generate_sentences_recursive_with_max_loop_count(model=\"openhermes\", word=word, n=5, loop=20)\n",
    "        if len(sentences) >= 5:\n",
    "            existing_data[word] = sentences\n",
    "            print(f\"{word}:\")\n",
    "            for sentence in sentences:\n",
    "                print(f\"\\t{sentence}\")\n",
    "\n",
    "            # Append the new word data to the file immediately\n",
    "            with open(file_path, 'w') as outfile:\n",
    "                json.dump(existing_data, outfile, indent=2)\n",
    "        else:\n",
    "            print(f\"Warning: Less than 3 valid sentences generated for word '{word}'\")\n",
    "        \n",
    "        words_processed.append(word)\n",
    "        word_end_time = time.time()\n",
    "    \n",
    "    level_end_time = time.time()\n",
    "    print(f\"Level {level} processed {len(words_processed)} in {level_end_time - level_start_time:.2f} seconds.\")\n",
    "    print(f\"Average time per word: {(level_end_time - level_start_time) / (len(words_processed)+1):.2f} seconds.\")\n",
    "    print(f\"Total time elapsed: {level_end_time - start_time:.2f} seconds.\")\n",
    "    print(f\"Average time per 200 words: {(level_end_time - start_time) / (len(existing_data)+1) * 200 / 60:.2f} minutes.\")\n",
    "\n",
    "print(\"Processing complete! New sentences appended to the file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
